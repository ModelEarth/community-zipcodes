{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Database\n",
    "\n",
    "In this notebook, we will perform the following steps to export data from a DuckDB database:\n",
    "1. Initialize the DataExporter class.\n",
    "2. Export data for all ZIP codes and industry levels.\n",
    "3. Verify the export results.\n",
    "\n",
    "This notebook will use the `DataExporter` class to handle data extraction and export operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import duckdb\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import query as q\n",
    "from duck_db_exporter import DataExporter  # Assuming DataExporter is defined in data_exporter.py\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DataQueryManager', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'csv', 'duckdb', 'os', 'pd']\n"
     ]
    }
   ],
   "source": [
    "import query\n",
    "print(dir(query))  # List all attributes and classes in the package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Export Database\n",
    "- this is in the jupyterversion, there will also be a script version that be used by github action soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataExporter\n",
    "exporter = DataExporter(\n",
    "    base_db_path='../zip_data/duck_db_manager/database/',\n",
    "    threads=4,\n",
    "    export_dir='../../US/zip',\n",
    "    industry_levels=[2, 5, 6],  # Specify industry levels if needed\n",
    "    year=2019  # Specify the year for the data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CA', 'GA', 'MA', 'UT', 'NV', 'SD', 'WA', 'ME', 'KY', 'NH', 'CT', 'RI', 'TN', 'SC', 'IA', 'ND', 'PA', 'OH', 'IN', 'NE', 'WI', 'LA', 'HI', 'DC', 'CO', 'AZ', 'MD', 'VA', 'NM', 'MO', 'OR', 'OK', 'NC', 'KS', 'MN', 'ID', 'AR', 'TX', 'WV', 'AK', 'FL', 'VT', None, 'MI', 'AL', 'MS', 'WY', 'IL', 'NY', 'NJ', 'MT', 'DE']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Export data for all states\u001b[39;00m\n\u001b[1;32m      2\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m exporter\u001b[38;5;241m.\u001b[39mmake_csv()  \u001b[38;5;66;03m# No state specified\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m file_paths:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExported file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Export data for all states\n",
    "file_paths = exporter.make_csv()  # No state specified\n",
    "\n",
    "for file_path in file_paths:\n",
    "    print(f\"Exported file: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Unit Test After Export\n",
    "\n",
    "In this section, we will validate the consistency of the exported CSV files with the original DuckDB database. The tests will ensure that the exported files contain the expected data and match the data from the database.\n",
    "\n",
    "We will perform the following tests:\n",
    "1. Check the number of rows in the exported CSV files.\n",
    "2. Validate that the data in the CSV files matches the data in the DuckDB database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
